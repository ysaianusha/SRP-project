{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9aa560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder # to encode lables as integers\n",
    "from sklearn.metrics import confusion_matrix  # built to derive raw accuracy, sensitivity, and specificity.\n",
    "from sklearn.metrics import accuracy_score # built to derive accuracy\n",
    "from skimage import feature  #HOG will come from here\n",
    "from imutils import build_montages #for visualization\n",
    "from imutils import paths  #helps to extract image path in dataset\n",
    "import numpy as np  #help statistics and grab random indices\n",
    "import cv2   #used to read, process, and display images\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6db957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to quantify image\n",
    "#this function is used to extract all the features from images\n",
    "def quantify_image(image):\n",
    "    #HOG is structural descripter that will capture and quantify changes in local gradient in the input image.\n",
    "    features = feature.hog(image,orientations=9, pixels_per_cell =(10,10),cells_per_block=(2,2) ,transform_sqrt=True, block_norm =\"L1\")\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a886dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(path):\n",
    "\t# grab the list of images in the input directory, then initialize\n",
    "\t# the list of data (i.e., images) and class labels\n",
    "\timagePaths = list(paths.list_images(path))\n",
    "\tdata = []\n",
    "\tlabels = []\n",
    "\t# loop over the image paths\n",
    "\tfor imagePath in imagePaths:\n",
    "\t\t# extract the class label from the filename\n",
    "\t\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\t\t# load the input image, convert it to grayscale, and resize\n",
    "\t\t# it to 200x200 pixels, ignoring aspect ratio\n",
    "\t\timage = cv2.imread(imagePath)\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\timage = cv2.resize(image, (200, 200))\n",
    "\t\t# threshold the image such that the drawing appears as white\n",
    "\t\t# on a black background\n",
    "\t\timage = cv2.threshold(image, 0, 255,\n",
    "\t\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\t\t# quantify the image\n",
    "\t\tfeatures = quantify_image(image)\n",
    "\t\t# update the data and labels lists, respectively\n",
    "\t\tdata.append(features)\n",
    "\t\tlabels.append(label)\n",
    "\t# return the data and labels\n",
    "\treturn (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c59d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spiral', 'wave']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"C:/Users/ysaia/Desktop/2-SEMISTER-2/SRP/sindhura-parkinsons-detection-main/sindhura-parkinsons-detection-main/dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c98f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_spiral=\"C:/Users/ysaia/Desktop/2-SEMISTER-2/SRP/sindhura-parkinsons-detection-main/sindhura-parkinsons-detection-main/dataset/spiral\"\n",
    "path_wave=\"C:/Users/ysaia/Desktop/2-SEMISTER-2/SRP/sindhura-parkinsons-detection-main/sindhura-parkinsons-detection-main/dataset/wave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f40e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingpath=os.path.sep.join([path_spiral,\"training\"])\n",
    "testingpath=os.path.sep.join([path_spiral,\"testing\"])\n",
    "trainingpath1=os.path.sep.join([path_wave,\"training\"])\n",
    "testingpath1=os.path.sep.join([path_wave,\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98489be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading spiral data...\n",
      "[INFO] loading wave data...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading spiral data...\")\n",
    "(trainX, trainY) = load_split(trainingpath)\n",
    "(testX, testY) = load_split(testingpath)\n",
    "print(\"[INFO] loading wave data...\")\n",
    "(trainX1, trainY1) = load_split(trainingpath1)\n",
    "(testX1, testY1) = load_split(testingpath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d09ce375",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "trainY=le.fit_transform(trainY)\n",
    "testY=le.transform(testY)\n",
    "trainY1=le.fit_transform(trainY1)\n",
    "testY1=le.transform(testY1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eecaaabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model 1 of 5...\n",
      "[INFO] training model 2 of 5...\n",
      "[INFO] training model 3 of 5...\n",
      "[INFO] training model 4 of 5...\n",
      "[INFO] training model 5 of 5...\n"
     ]
    }
   ],
   "source": [
    "trails={}\n",
    "# loop over the number of trials to run\n",
    "for i in range(0, 5):\n",
    "\t# train the model\n",
    "\tprint(\"[INFO] training model {} of {}...\".format(i + 1,5))\n",
    "\tmodel = RandomForestClassifier(n_estimators=100)\n",
    "\tmodel.fit(trainX, trainY)\n",
    "\t# make predictions on the testing data and initialize a dictionary\n",
    "\t# to store our computed metrics\n",
    "\tpredictions = model.predict(testX)\n",
    "\tmetrics = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f12b0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR SPIRAL DATASET\n",
      "accuracy\n",
      "========\n",
      "u=0.8000, o=0.0000\n",
      "\n",
      "sensitivity\n",
      "===========\n",
      "u=0.6667, o=0.0000\n",
      "\n",
      "specificity\n",
      "===========\n",
      "u=0.9333, o=0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(testY, predictions)\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "metrics[\"accuracy\"] = (tp + tn) / float(cm.sum())\n",
    "metrics[\"sensitivity\"] = tp / float(tp + fn)\n",
    "metrics[\"specificity\"] = tn / float(tn + fp)\n",
    "\n",
    "for (k, v) in metrics.items():\n",
    "    l = trails.get(k, [])\n",
    "    l.append(v)\n",
    "    trails[k] = l\n",
    "print(\"FOR SPIRAL DATASET\")\n",
    "for metric in (\"accuracy\", \"sensitivity\", \"specificity\"):\n",
    "\tvalues = trails[metric]\n",
    "\tmean = np.mean(values)\n",
    "\tstd = np.std(values)\n",
    "\n",
    "\tprint(metric)\n",
    "\tprint(\"=\" * len(metric))\n",
    "\tprint(\"u={:.4f}, o={:.4f}\".format(mean, std))\n",
    "\tprint(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b2fd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingpaths = list(paths.list_images(testingpath))\n",
    "idxs = np.arange(0, len(testingpaths))\n",
    "idxs = np.random.choice(idxs, size=(25,), replace=False)\n",
    "images = []\n",
    "\n",
    "for i in idxs:\n",
    "\timage = cv2.imread(testingpaths[i])\n",
    "\toutput = image.copy()\n",
    "\toutput = cv2.resize(output, (128, 128))\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\timage = cv2.resize(image, (200, 200))\n",
    "\timage = cv2.threshold(image, 0, 255,\n",
    "\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\tfeatures = quantify_image(image)\n",
    "\tpreds = model.predict([features])\n",
    "\tlabel = le.inverse_transform(preds)[0]\n",
    "\n",
    "\tcolor =(0,255,0) if label == \"healthy\" else (0, 0, 255)\n",
    "\tcv2.putText(output, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "\t\tcolor, 2)\n",
    "\timages.append(output)\n",
    "montage = build_montages(images, (128, 128), (5, 5))[0]\n",
    "\n",
    "cv2.imshow(\"Output spiral\", montage)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcdf0502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model 1 of 5...\n",
      "[INFO] training model 2 of 5...\n",
      "[INFO] training model 3 of 5...\n",
      "[INFO] training model 4 of 5...\n",
      "[INFO] training model 5 of 5...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loop over the number of trials to run\n",
    "for i in range(0, 5):\n",
    "\t# train the model\n",
    "\tprint(\"[INFO] training model {} of {}...\".format(i + 1,5))\n",
    "\tmodel = RandomForestClassifier(n_estimators=100)\n",
    "\tmodel.fit(trainX1, trainY1)\n",
    "\t# make predictions on the testing data and initialize a dictionary\n",
    "\t# to store our computed metrics\n",
    "\tpredictions1 = model.predict(testX1)\n",
    "\tmetrics1 = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "537cd448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR WAVE DATA SET\n",
      "accuracy\n",
      "========\n",
      "u=0.7833, o=0.0167\n",
      "\n",
      "sensitivity\n",
      "===========\n",
      "u=0.7000, o=0.0333\n",
      "\n",
      "specificity\n",
      "===========\n",
      "u=0.8667, o=0.0667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm1 = confusion_matrix(testY1, predictions1)\n",
    "tn=cm1[0][0]\n",
    "fp=cm1[0][1]\n",
    "fn=cm1[1][0]\n",
    "tp=cm1[1][1]\n",
    "metrics1[\"accuracy\"] = (tp + tn) / float(cm1.sum())\n",
    "metrics1[\"sensitivity\"] = tp / float(tp + fn)\n",
    "metrics1[\"specificity\"] = tn / float(tn + fp)\n",
    "\n",
    "for (k, v) in metrics1.items():\n",
    "    l = trails.get(k, [])\n",
    "    l.append(v)\n",
    "    trails[k] = l\n",
    "print(\"FOR WAVE DATA SET\")\n",
    "for metric in (\"accuracy\", \"sensitivity\", \"specificity\"):\n",
    "\tvalues = trails[metric]\n",
    "\tmean = np.mean(values)\n",
    "\tstd = np.std(values)\n",
    "\n",
    "\tprint(metric)\n",
    "\tprint(\"=\" * len(metric))\n",
    "\tprint(\"u={:.4f}, o={:.4f}\".format(mean, std))\n",
    "\tprint(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a58b3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingpaths1 = list(paths.list_images(testingpath1))\n",
    "idxs = np.arange(0, len(testingpaths1))\n",
    "idxs = np.random.choice(idxs, size=(25,), replace=False)\n",
    "images = []\n",
    "\n",
    "for i in idxs:\n",
    "\timage = cv2.imread(testingpaths1[i])\n",
    "\toutput = image.copy()\n",
    "\toutput = cv2.resize(output, (128, 128))\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\timage = cv2.resize(image, (200, 200))\n",
    "\timage = cv2.threshold(image, 0, 255,\n",
    "\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\tfeatures = quantify_image(image)\n",
    "\tpreds = model.predict([features])\n",
    "\tlabel = le.inverse_transform(preds)[0]\n",
    "\n",
    "\tcolor =(0,255,0) if label == \"healthy\" else (0, 0, 255)\n",
    "\tcv2.putText(output, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "\t\tcolor, 2)\n",
    "\timages.append(output)\n",
    "montage = build_montages(images, (128, 128), (5, 5))[0]\n",
    "\n",
    "cv2.imshow(\"Output\", montage)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e0dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of model for spiral dataset 0.8\n",
      "accuracy of model for wave datase 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "s_score = accuracy_score(testY,predictions)\n",
    "print(\"accuracy of model for spiral dataset\",s_score)\n",
    "w_score = accuracy_score(testY1,predictions1)\n",
    "print(\"accuracy of model for wave datase\",w_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5b1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
